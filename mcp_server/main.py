# generated by fastapi-codegen:
#   filename:  openapi.yaml
#   timestamp: 2025-06-28T18:28:10+00:00



import argparse
import json
import os
from typing import *

from autogen.mcp.mcp_proxy import MCPProxy
from autogen.mcp.mcp_proxy.security import APIKeyQuery, BaseSecurity

from models import (
    Fetchrequest,
    ParsePostResponse,
    Parserequest,
    SerpPostResponse,
    Serprequest,
    Url2pdfrequest,
    Url2screenshotrequest,
)

app = MCPProxy(
    contact={'url': 'https://dataflowkit.com/'},
    description='Render Javascript driven pages, while we internally manage Headless Chrome and proxies for you. \n\n- Build a custom web scraper with our Visual point-and-click toolkit.\n- Scrape the most popular Search engines result pages (SERP).\n- Convert web pages to PDF and capture screenshots.\n***\n### Authentication\nDataflow Kit API require you to sign up for an API key in order to use the API. \n\nThe API key can be found in the [DFK Dashboard](https://account.dataflowkit.com) after _free registration_.\n\nPass a secret API Key to all API requests to the server as the `api_key` query parameter. \n',
    termsOfService='https://dataflowkit.com/terms',
    title='Dataflow Kit Web Scraper',
    version='1.3',
    servers=[
        {'description': 'Production server', 'url': 'https://api.dataflowkit.com/v1'}
    ],
)


@app.post(
    '/convert/url/pdf',
    description=""" Automate URL to PDF Conversion right in your application.

Specify request parameters like URL, Proxy, and actions to render web pages to PDF using Headless Chrome.

Get resulted PDF even from websites blocked in your area for some reason utilizing our worldwide pool of proxies.

Simulate real-world human interaction with the page. For example, before saving a web page to PDF, you may need to scroll it.

Generate ready-to-run code for your favorite language at [https://dataflowkit.com/url-to-pdf](https://dataflowkit.com/url-to-pdf) """,
    tags=['web_page_operations'],
    security=[
        APIKeyQuery(name="api_key"),
    ],
)
def url_to_pdf(body: Url2pdfrequest):
    """
    Save web page as PDF
    """
    raise RuntimeError("Should be patched by MCPProxy and never executed")


@app.post(
    '/convert/url/screenshot',
    description=""" Automate URL to Screenshot Conversion right in your application.

Specify request parameters like URL, Proxy, and actions to convert web pages to screenshots using Headless Chrome.

Get resulted pictures in JPG or PNG formats even from websites blocked in your area for some reason utilizing our worldwide pool of proxies.

Simulate real-world human interaction with the page. For example, before capturing a web page, you may need to scroll it.

Generate ready-to-run code for your favorite language at [https://dataflowkit.com/url-to-screenshot](https://dataflowkit.com/url-to-screenshot) """,
    tags=['web_page_operations'],
    security=[
        APIKeyQuery(name="api_key"),
    ],
)
def url_to_screenshot(body: Url2screenshotrequest):
    """
    Capture web page Screenshots.
    """
    raise RuntimeError("Should be patched by MCPProxy and never executed")


@app.post(
    '/fetch',
    description=""" Use fetch endpoint to download web pages. """,
    tags=['web_page_operations'],
    security=[
        APIKeyQuery(name="api_key"),
    ],
)
def fetch(body: Fetchrequest):
    """
    Download web page content
    """
    raise RuntimeError("Should be patched by MCPProxy and never executed")


@app.post(
    '/parse',
    description=""" Dataflow kit uses CSS selectors to find HTML elements in web pages for later data extraction.

Open [visual point-and-click toolkit](https://dataflowkit.com/dfk) and click desired elements on a page to specify extracting data. 


 Then you can send generated payload to `/parse` endpoint. We crawl web pages and extract data like text, links, or images for you following the specified rules. 


Extracted data is returned in CSV, MS Excel, JSON, JSON(Lines) or XML format.
 """,
    tags=['structured_data_extraction'],
    security=[
        APIKeyQuery(name="api_key"),
    ],
)
def parse(body: Parserequest):
    """
    Extract structured data from web pages
    """
    raise RuntimeError("Should be patched by MCPProxy and never executed")


@app.post(
    '/serp',
    description=""" To crawl search engine result pages, you can use `/serp` endpoint. SERP collection service extracts a list of organic results, news, images, and more.  Specify configuration parameters, such as country or languages, to customize output SERP data.
The following search engines are supported

- google
- google-image
- google-news
- google-shopping
- bing
- duckduckgo
- baidu
- yandex


Generate ready-to-run code for your favorite language at [https://dataflowkit.com/serp](https://dataflowkit.com/serp) """,
    tags=['structured_data_extraction'],
    security=[
        APIKeyQuery(name="api_key"),
    ],
)
def serp(body: Serprequest):
    """
    Collect search results from search engines
    """
    raise RuntimeError("Should be patched by MCPProxy and never executed")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="MCP Server")
    parser.add_argument(
        "transport",
        choices=["stdio", "sse", "streamable-http"],
        help="Transport mode (stdio, sse or streamable-http)",
    )
    args = parser.parse_args()

    if "CONFIG_PATH" in os.environ:
        config_path = os.environ["CONFIG_PATH"]
        app.load_configuration(config_path)

    if "CONFIG" in os.environ:
        config = os.environ["CONFIG"]
        app.load_configuration_from_string(config)

    if "SECURITY" in os.environ:
        security_params = BaseSecurity.parse_security_parameters_from_env(
            os.environ,
        )

        app.set_security_params(security_params)

    mcp_settings = json.loads(os.environ.get("MCP_SETTINGS", "{}"))

    app.get_mcp(**mcp_settings).run(transport=args.transport)
